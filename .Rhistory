acs <- "https://dl.dropbox.com/u/7710864/data/csv_hid/ss06hid.csv"
download.file(acs, destfile = "housing.csv", method = "curl")
home <- read.table("housing.csv", header = TRUE, sep = ",")
summary(as.factor(home$VAL))
acs <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv "
acs
download.file(acs, destfile = "housing.csv", method = "curl")
acs
home <- read.table("housing.csv", header = TRUE, sep = ",")
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
utils:::menuInstallPkgs()
readJPEG(https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg, native = TRUE)
WD
wd()
wd
readJPEG(getdata%2Fjeff.jpg, native = TRUE)
readJPEG(getdata 2Fjeff.jpg, native = TRUE)
readJPEG
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
readJPEG(getdata%2Fjeff.jpg, native = TRUE)
readJPEG(https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg, native = TRUE)
img.n <- readJPEG(system.file("img", "getdata-jeff.jpg", package="jpeg"), TRUE)
readJPEG(getdata-jeff.jpg, native = TRUE)
readJPEG
readJPEG("getdata-jeff.jpg")
readJPEG("getdata-jeff.jpg" native=TRUE)
readJPEG
readJPEG("getdata-jeff.jpg", native=TRUE)
img <- readJPEG("getdata-jeff.jpg", native=TRUE)
img
img[30]
img
quantile(img, 30)
quantile
quanitle(img)
quantile(img)
quantile(img, 30)
quantile(img, probs=30)
quantile(img, probs=(.3, .8))
quantile(img, probs=c(.3, .8))
# Returns one data set by reading and merging all component files.
# Data set comprises of the X values, Y values and Subject IDs.
# The path_prefix indicates the path where the data files can be found.
# The fname_suffix indicates the file name suffix to be used to create the complete file name.
#
# This also subsets the data to extract only the measurements on the mean and standard deviation for each measurement.
# The required columns in the subset is determined by selecting only those columns that have either "mean()" or "std()" in their names.
# Subsetting is done early on to help reduce memory requirements.
readData <- function(fname_suffix, path_prefix) {
    fpath <- file.path(path_prefix, paste0("y_", fname_suffix, ".txt"))
    y_data <- read.table(fpath, header=F, col.names=c("ActivityID"))
    fpath <- file.path(path_prefix, paste0("subject_", fname_suffix, ".txt"))
    subject_data <- read.table(fpath, header=F, col.names=c("SubjectID"))
    # read the column names
    data_cols <- read.table("features.txt", header=F, as.is=T, col.names=c("MeasureID", "MeasureName"))
    # read the X data file
    fpath <- file.path(path_prefix, paste0("X_", fname_suffix, ".txt"))
    data <- read.table(fpath, header=F, col.names=data_cols$MeasureName)
    # names of subset columns required
    subset_data_cols <- grep(".*mean\\(\\)|.*std\\(\\)", data_cols$MeasureName)
    # subset the data (done early to save memory)
    data <- data[,subset_data_cols]
    # append the activity id and subject id columns
    data$ActivityID <- y_data$ActivityID
    data$SubjectID <- subject_data$SubjectID
    # return the data
    data
}
# read test data set, in a folder named "test", and data file names suffixed with "test"
readTestData <- function() {
    readData("test", "test")
}
# read test data set, in a folder named "train", and data file names suffixed with "train"
readTrainData <- function() {
    readData("train", "train")
}
# Merge both train and test data sets
# Also make the column names nicer
mergeData <- function() {
    data <- rbind(readTestData(), readTrainData())
    cnames <- colnames(data)
    cnames <- gsub("\\.+mean\\.+", cnames, replacement="Mean")
    cnames <- gsub("\\.+std\\.+",  cnames, replacement="Std")
    colnames(data) <- cnames
    data
}
# Add the activity names as another column
applyActivityLabel <- function(data) {
    activity_labels <- read.table("activity_labels.txt", header=F, as.is=T, col.names=c("ActivityID", "ActivityName"))
    activity_labels$ActivityName <- as.factor(activity_labels$ActivityName)
    data_labeled <- merge(data, activity_labels)
    data_labeled
}
# Combine training and test data sets and add the activity label as another column
getMergedLabeledData <- function() {
    applyActivityLabel(mergeData())
}
# Create a tidy data set that has the average of each variable for each activity and each subject.
getTidyData <- function(merged_labeled_data) {
    library(reshape2)
    # melt the dataset
    id_vars = c("ActivityID", "ActivityName", "SubjectID")
    measure_vars = setdiff(colnames(merged_labeled_data), id_vars)
    melted_data <- melt(merged_labeled_data, id=id_vars, measure.vars=measure_vars)
    # recast 
    dcast(melted_data, ActivityName + SubjectID ~ variable, mean)    
}
# Create the tidy data set and save it on to the named file
createTidyDataFile <- function(fname) {
    tidy_data <- getTidyData(getMergedLabeledData())
    write.table(tidy_data, fname)
}
print("Assuming data files from the \"UCI HAR Dataset\" are availale in the current directory with the same structure as in the downloaded archive.")
print("    Refer Data:")
print("    archive: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip")
print("    description: dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones")
print("Creating tidy dataset as tidy.txt...")
createTidyDataFile("tidy.txt")
print("Done.")
# Returns one data set by reading and merging all component files.
# Data set comprises of the X values, Y values and Subject IDs.
# The path_prefix indicates the path where the data files can be found.
# The fname_suffix indicates the file name suffix to be used to create the complete file name.
#
# This also subsets the data to extract only the measurements on the mean and standard deviation for each measurement.
# The required columns in the subset is determined by selecting only those columns that have either "mean()" or "std()" in their names.
# Subsetting is done early on to help reduce memory requirements.
readData <- function(fname_suffix, path_prefix) {
    fpath <- file.path(path_prefix, paste0("y_", fname_suffix, ".txt"))
    y_data <- read.table(fpath, header=F, col.names=c("ActivityID"))
    fpath <- file.path(path_prefix, paste0("subject_", fname_suffix, ".txt"))
    subject_data <- read.table(fpath, header=F, col.names=c("SubjectID"))
    # read the column names
    data_cols <- read.table("features.txt", header=F, as.is=T, col.names=c("MeasureID", "MeasureName"))
    # read the X data file
    fpath <- file.path(path_prefix, paste0("X_", fname_suffix, ".txt"))
    data <- read.table(fpath, header=F, col.names=data_cols$MeasureName)
    # names of subset columns required
    subset_data_cols <- grep(".*mean\\(\\)|.*std\\(\\)", data_cols$MeasureName)
    # subset the data (done early to save memory)
    data <- data[,subset_data_cols]
    # append the activity id and subject id columns
    data$ActivityID <- y_data$ActivityID
    data$SubjectID <- subject_data$SubjectID
    # return the data
    data
}
# read test data set, in a folder named "test", and data file names suffixed with "test"
readTestData <- function() {
    readData("test", "test")
}
# read test data set, in a folder named "train", and data file names suffixed with "train"
readTrainData <- function() {
    readData("train", "train")
}
# Merge both train and test data sets
# Also make the column names nicer
mergeData <- function() {
    data <- rbind(readTestData(), readTrainData())
    cnames <- colnames(data)
    cnames <- gsub("\\.+mean\\.+", cnames, replacement="Mean")
    cnames <- gsub("\\.+std\\.+",  cnames, replacement="Std")
    colnames(data) <- cnames
    data
}
# Add the activity names as another column
applyActivityLabel <- function(data) {
    activity_labels <- read.table("activity_labels.txt", header=F, as.is=T, col.names=c("ActivityID", "ActivityName"))
    activity_labels$ActivityName <- as.factor(activity_labels$ActivityName)
    data_labeled <- merge(data, activity_labels)
    data_labeled
}
# Combine training and test data sets and add the activity label as another column
getMergedLabeledData <- function() {
    applyActivityLabel(mergeData())
}
# Create a tidy data set that has the average of each variable for each activity and each subject.
getTidyData <- function(merged_labeled_data) {
    library(reshape2)
    # melt the dataset
    id_vars = c("ActivityID", "ActivityName", "SubjectID")
    measure_vars = setdiff(colnames(merged_labeled_data), id_vars)
    melted_data <- melt(merged_labeled_data, id=id_vars, measure.vars=measure_vars)
    # recast 
    dcast(melted_data, ActivityName + SubjectID ~ variable, mean)    
}
# Create the tidy data set and save it on to the named file
createTidyDataFile <- function(fname) {
    tidy_data <- getTidyData(getMergedLabeledData())
    write.table(tidy_data, fname)
}
print("Assuming data files from the \"UCI HAR Dataset\" are availale in the current directory with the same structure as in the downloaded archive.")
print("    Refer Data:")
print("    archive: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip")
print("    description: dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones")
print("Creating tidy dataset as tidy.txt...")
createTidyDataFile("tidy.txt")
print("Done.")
utils:::menuInstallPkgs()
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
# Returns one data set by reading and merging all component files.
# Data set comprises of the X values, Y values and Subject IDs.
# The path_prefix indicates the path where the data files can be found.
# The fname_suffix indicates the file name suffix to be used to create the complete file name.
#
# This also subsets the data to extract only the measurements on the mean and standard deviation for each measurement.
# The required columns in the subset is determined by selecting only those columns that have either "mean()" or "std()" in their names.
# Subsetting is done early on to help reduce memory requirements.
readData <- function(fname_suffix, path_prefix) {
    fpath <- file.path(path_prefix, paste0("y_", fname_suffix, ".txt"))
    y_data <- read.table(fpath, header=F, col.names=c("ActivityID"))
    fpath <- file.path(path_prefix, paste0("subject_", fname_suffix, ".txt"))
    subject_data <- read.table(fpath, header=F, col.names=c("SubjectID"))
    # read the column names
    data_cols <- read.table("features.txt", header=F, as.is=T, col.names=c("MeasureID", "MeasureName"))
    # read the X data file
    fpath <- file.path(path_prefix, paste0("X_", fname_suffix, ".txt"))
    data <- read.table(fpath, header=F, col.names=data_cols$MeasureName)
    # names of subset columns required
    subset_data_cols <- grep(".*mean\\(\\)|.*std\\(\\)", data_cols$MeasureName)
    # subset the data (done early to save memory)
    data <- data[,subset_data_cols]
    # append the activity id and subject id columns
    data$ActivityID <- y_data$ActivityID
    data$SubjectID <- subject_data$SubjectID
    # return the data
    data
}
# read test data set, in a folder named "test", and data file names suffixed with "test"
readTestData <- function() {
    readData("test", "test")
}
# read test data set, in a folder named "train", and data file names suffixed with "train"
readTrainData <- function() {
    readData("train", "train")
}
# Merge both train and test data sets
# Also make the column names nicer
mergeData <- function() {
    data <- rbind(readTestData(), readTrainData())
    cnames <- colnames(data)
    cnames <- gsub("\\.+mean\\.+", cnames, replacement="Mean")
    cnames <- gsub("\\.+std\\.+",  cnames, replacement="Std")
    colnames(data) <- cnames
    data
}
# Add the activity names as another column
applyActivityLabel <- function(data) {
    activity_labels <- read.table("activity_labels.txt", header=F, as.is=T, col.names=c("ActivityID", "ActivityName"))
    activity_labels$ActivityName <- as.factor(activity_labels$ActivityName)
    data_labeled <- merge(data, activity_labels)
    data_labeled
}
# Combine training and test data sets and add the activity label as another column
getMergedLabeledData <- function() {
    applyActivityLabel(mergeData())
}
# Create a tidy data set that has the average of each variable for each activity and each subject.
getTidyData <- function(merged_labeled_data) {
    library(reshape2)
    # melt the dataset
    id_vars = c("ActivityID", "ActivityName", "SubjectID")
    measure_vars = setdiff(colnames(merged_labeled_data), id_vars)
    melted_data <- melt(merged_labeled_data, id=id_vars, measure.vars=measure_vars)
    # recast 
    dcast(melted_data, ActivityName + SubjectID ~ variable, mean)    
}
# Create the tidy data set and save it on to the named file
createTidyDataFile <- function(fname) {
    tidy_data <- getTidyData(getMergedLabeledData())
    write.table(tidy_data, fname)
}
print("Assuming data files from the \"UCI HAR Dataset\" are availale in the current directory with the same structure as in the downloaded archive.")
print("    Refer Data:")
print("    archive: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip")
print("    description: dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones")
print("Creating tidy dataset as tidy.txt...")
createTidyDataFile("tidy.txt")
print("Done.")
# Returns one data set by reading and merging all component files.
# Data set comprises of the X values, Y values and Subject IDs.
# The path_prefix indicates the path where the data files can be found.
# The fname_suffix indicates the file name suffix to be used to create the complete file name.
#
# This also subsets the data to extract only the measurements on the mean and standard deviation for each measurement.
# The required columns in the subset is determined by selecting only those columns that have either "mean()" or "std()" in their names.
# Subsetting is done early on to help reduce memory requirements.
readData <- function(fname_suffix, path_prefix) {
    fpath <- file.path(path_prefix, paste0("y_", fname_suffix, ".txt"))
    y_data <- read.table(fpath, header=F, col.names=c("ActivityID"))
    fpath <- file.path(path_prefix, paste0("subject_", fname_suffix, ".txt"))
    subject_data <- read.table(fpath, header=F, col.names=c("SubjectID"))
    # read the column names
    data_cols <- read.table("features.txt", header=F, as.is=T, col.names=c("MeasureID", "MeasureName"))
    # read the X data file
    fpath <- file.path(path_prefix, paste0("X_", fname_suffix, ".txt"))
    data <- read.table(fpath, header=F, col.names=data_cols$MeasureName)
    # names of subset columns required
    subset_data_cols <- grep(".*mean\\(\\)|.*std\\(\\)", data_cols$MeasureName)
    # subset the data (done early to save memory)
    data <- data[,subset_data_cols]
    # append the activity id and subject id columns
    data$ActivityID <- y_data$ActivityID
    data$SubjectID <- subject_data$SubjectID
    # return the data
    data
}
# read test data set, in a folder named "test", and data file names suffixed with "test"
readTestData <- function() {
    readData("test", "test")
}
# read test data set, in a folder named "train", and data file names suffixed with "train"
readTrainData <- function() {
    readData("train", "train")
}
# Merge both train and test data sets
# Also make the column names nicer
mergeData <- function() {
    data <- rbind(readTestData(), readTrainData())
    cnames <- colnames(data)
    cnames <- gsub("\\.+mean\\.+", cnames, replacement="Mean")
    cnames <- gsub("\\.+std\\.+",  cnames, replacement="Std")
    colnames(data) <- cnames
    data
}
# Add the activity names as another column
applyActivityLabel <- function(data) {
    activity_labels <- read.table("activity_labels.txt", header=F, as.is=T, col.names=c("ActivityID", "ActivityName"))
    activity_labels$ActivityName <- as.factor(activity_labels$ActivityName)
    data_labeled <- merge(data, activity_labels)
    data_labeled
}
# Combine training and test data sets and add the activity label as another column
getMergedLabeledData <- function() {
    applyActivityLabel(mergeData())
}
# Create a tidy data set that has the average of each variable for each activity and each subject.
getTidyData <- function(merged_labeled_data) {
    library(reshape2)
    # melt the dataset
    id_vars = c("ActivityID", "ActivityName", "SubjectID")
    measure_vars = setdiff(colnames(merged_labeled_data), id_vars)
    melted_data <- melt(merged_labeled_data, id=id_vars, measure.vars=measure_vars)
    # recast 
    dcast(melted_data, ActivityName + SubjectID ~ variable, mean)    
}
# Create the tidy data set and save it on to the named file
createTidyDataFile <- function(fname) {
    tidy_data <- getTidyData(getMergedLabeledData())
    write.table(tidy_data, fname)
}
print("Assuming data files from the \"UCI HAR Dataset\" are availale in the current directory with the same structure as in the downloaded archive.")
print("    Refer Data:")
print("    archive: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip")
print("    description: dataset: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones")
print("Creating tidy dataset as tidy.txt...")
createTidyDataFile("tidy.txt")
print("Done.")
# Memory is an issue so subset the data early
readData <- function(fname_suffix, path_prefix) {
    fpath <- file.path(path_prefix, paste0("y_", fname_suffix, ".txt"))
    y_data <- read.table(fpath, header=F, col.names=c("ActivityID"))    
    fpath <- file.path(path_prefix, paste0("subject_", fname_suffix, ".txt"))
    subject_data <- read.table(fpath, header=F, col.names=c("SubjectID"))  
    data_cols <- read.table("features.txt", header=F, as.is=T, col.names=c("MeasureID", "MeasureName"))
    fpath <- file.path(path_prefix, paste0("X_", fname_suffix, ".txt"))
    data <- read.table(fpath, header=F, col.names=data_cols$MeasureName)
    subset_data_cols <- grep(".*mean\\(\\)|.*std\\(\\)", data_cols$MeasureName)
    data <- data[,subset_data_cols]
    data$ActivityID <- y_data$ActivityID
    data$SubjectID <- subject_data$SubjectID
    data
}
# read test data set, in a folder named "test", and data file names suffixed with "test"
readTestData <- function() {
    readData("test", "test")
}
# read test data set, in a folder named "train", and data file names suffixed with "train"
readTrainData <- function() {
    readData("train", "train")
}
# Merge both train and test data sets
# Also make the column names nicer
mergeData <- function() {
    data <- rbind(readTestData(), readTrainData())
    cnames <- colnames(data)
    cnames <- gsub("\\.+mean\\.+", cnames, replacement="Mean")
    cnames <- gsub("\\.+std\\.+",  cnames, replacement="Std")
    colnames(data) <- cnames
    data
}
# Add the activity names as another column
applyActivityLabel <- function(data) {
    activity_labels <- read.table("activity_labels.txt", header=F, as.is=T, col.names=c("ActivityID", "ActivityName"))
    activity_labels$ActivityName <- as.factor(activity_labels$ActivityName)
    data_labeled <- merge(data, activity_labels)
    data_labeled
}
# Combine training and test data sets and add the activity label as another column
getMergedLabeledData <- function() {
    applyActivityLabel(mergeData())
}
# Create a tidy data set that has the average of each variable for each activity and each subject.
getTidyData <- function(merged_labeled_data) {
    library(reshape2)    
    id_vars = c("ActivityID", "ActivityName", "SubjectID")
    measure_vars = setdiff(colnames(merged_labeled_data), id_vars)
    melted_data <- melt(merged_labeled_data, id=id_vars, measure.vars=measure_vars)
    dcast(melted_data, ActivityName + SubjectID ~ variable, mean)    
}
# Tidy the data and create a specified file name that is passed to the function.
createTidyData <- function(fname) {
    tidy_data <- getTidyData(getMergedLabeledData())
    write.table(tidy_data, fname)
}
print("Tidying up the data, please stand by.")
createTidyData("TidyData.txt")
print("Done.")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn) 
library(quantmod)
utils:::menuInstallPkgs()
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn) 
sampleTimes
as.data.frame(table(sampleTimes))
numbers Freq
sampleTimes Freq
wd
/wd
dir
dir()
dir()
# plot1.R - Histogram of Global Active Power
# Read data, convert dates and subset on two days in February 2007
data <- read.table('../household_power_consumption.txt', sep=';', header=T, 
                   colClasses = c('character', 'character', 'numeric',
                                  'numeric', 'numeric', 'numeric',
                                  'numeric', 'numeric', 'numeric'),
                   na.strings='?')
data$DateTime <- strptime(paste(data$Date, data$Time), 
                          "%d/%m/%Y %H:%M:%S")
data <- subset(data, 
       as.Date(DateTime) >= as.Date("2007-02-01") & 
           as.Date(DateTime) <= as.Date("2007-02-02"))
# Open plot1.png
png("plot1.png", height=480, width=480)
# Build histogram
hist(data$Global_active_power, col='red', 
     xlab = 'Global Active Power (kilowatts)',
     main = 'Global Active Power')
# Close PNG file
dev.off()
dir()
data <- read.table('../household_power_consumption.txt', sep=';', header=T, 
                   colClasses = c('character', 'character', 'numeric',
                                  'numeric', 'numeric', 'numeric',
                                  'numeric', 'numeric', 'numeric'),
                   na.strings='?')
data <- read.table('household_power_consumption.txt', sep=';', header=T, 
                   colClasses = c('character', 'character', 'numeric',
                                  'numeric', 'numeric', 'numeric',
                                  'numeric', 'numeric', 'numeric'),
                   na.strings='?')
data$DateTime <- strptime(paste(data$Date, data$Time), 
                          "%d/%m/%Y %H:%M:%S")
data <- subset(data, 
       as.Date(DateTime) >= as.Date("2007-02-01") & 
           as.Date(DateTime) <= as.Date("2007-02-02"))
# Open plot1.png
png("plot1.png", height=480, width=480)
# Build histogram
hist(data$Global_active_power, col='red', 
     xlab = 'Global Active Power (kilowatts)',
     main = 'Global Active Power')
# plot1.R - Histogram of Global Active Power
# Read data, convert dates and subset on two days in February 2007
data <- read.table('household_power_consumption.txt', sep=';', header=T, 
                   colClasses = c('character', 'character', 'numeric',
                                  'numeric', 'numeric', 'numeric',
                                  'numeric', 'numeric', 'numeric'),
                   na.strings='?')
data$DateTime <- strptime(paste(data$Date, data$Time), 
                          "%d/%m/%Y %H:%M:%S")
data <- subset(data, 
       as.Date(DateTime) >= as.Date("2007-02-01") & 
           as.Date(DateTime) <= as.Date("2007-02-02"))
# Open plot1.png
png("plot1.png", height=480, width=480)
# Build histogram
hist(data$Global_active_power, col='red', 
     xlab = 'Global Active Power (kilowatts)',
     main = 'Global Active Power')
# Close PNG file
dev.off()
q()
